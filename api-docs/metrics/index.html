<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Metrics - GReaT</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Metrics";
        var mkdocs_page_input_path = "api-docs/metrics.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> GReaT
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../getting_started/">Getting Started</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../about/">About</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">API Reference</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../great/">GReaT</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../great_dataset/">GReaTDataset</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../great_start/">GReaTStart</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../great_trainer/">GReaTTrainer</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Examples</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/Example_Iris/">Example Iris</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/Example_California_Housing/">Example California Housing</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">GReaT</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">API Reference</li>
      <li class="breadcrumb-item active">Metrics</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <!-- markdownlint-disable -->

<h1 id="module-metrics"><kbd>module</kbd> <code>metrics</code></h1>
<p>Built-in evaluation suite for measuring the quality, utility, and privacy of synthetic tabular data generated by GReaT. All metrics inherit from <code>BaseMetric</code> and share a common interface:</p>
<pre><code class="language-python">result = SomeMetric().compute(real_data, synthetic_data)
</code></pre>
<p>Column types (numerical / categorical) are auto-detected but can be passed explicitly via <code>num_cols</code> and <code>cat_cols</code>.</p>
<hr />
<h2 id="class-basemetric"><kbd>class</kbd> <code>BaseMetric</code></h2>
<p>Abstract base class for all GReaT evaluation metrics.</p>
<p>Subclasses must implement <code>name()</code>, <code>direction()</code>, and <code>compute()</code>.</p>
<p><strong>Methods:</strong></p>
<ul>
<li><b><code>name()</code></b> → str: Human-readable metric name</li>
<li><b><code>direction()</code></b> → str: <code>"maximize"</code> if higher is better, <code>"minimize"</code> if lower is better</li>
<li><b><code>compute(real_data, synthetic_data, **kwargs)</code></b> → dict: Compute the metric</li>
</ul>
<hr />
<h2 id="statistical-metrics">Statistical Metrics</h2>
<h3 id="class-columnshapes"><kbd>class</kbd> <code>ColumnShapes</code></h3>
<p>Per-column distribution similarity.</p>
<p>Uses the Kolmogorov-Smirnov test for numerical columns and Total Variation Distance for categorical columns. Returns a score in [0, 1] per column — 1.0 means identical distributions.</p>
<pre><code class="language-python">from be_great.metrics import ColumnShapes

result = ColumnShapes().compute(real_data, synthetic_data)
# result[&quot;column_shapes_mean&quot;]   -&gt; average similarity across all columns
# result[&quot;column_shapes_std&quot;]    -&gt; standard deviation
# result[&quot;column_shapes_detail&quot;] -&gt; per-column scores dict
</code></pre>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>num_cols</code></b> (list, optional): Numerical column names</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
</ul>
<hr />
<h3 id="class-columnpairtrends"><kbd>class</kbd> <code>ColumnPairTrends</code></h3>
<p>Pairwise correlation preservation.</p>
<p>Compares Pearson correlations for numerical pairs and Cramer's V for categorical pairs between real and synthetic data. Returns a score in [0, 1] — 1.0 means identical pairwise relationships.</p>
<pre><code class="language-python">from be_great.metrics import ColumnPairTrends

result = ColumnPairTrends().compute(real_data, synthetic_data)
# result[&quot;column_pair_trends_mean&quot;]        -&gt; overall similarity
# result[&quot;column_pair_trends_numerical&quot;]   -&gt; numerical pair similarity
# result[&quot;column_pair_trends_categorical&quot;] -&gt; categorical pair similarity
</code></pre>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>num_cols</code></b> (list, optional): Numerical column names</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
</ul>
<hr />
<h3 id="class-basicstatistics"><kbd>class</kbd> <code>BasicStatistics</code></h3>
<p>Summary statistics comparison.</p>
<p>Compares mean, standard deviation, and median for numerical columns, and category frequency distributions for categorical columns.</p>
<pre><code class="language-python">from be_great.metrics import BasicStatistics

result = BasicStatistics().compute(real_data, synthetic_data)
# result[&quot;basic_statistics&quot;][&quot;col_name&quot;][&quot;real_mean&quot;]
# result[&quot;basic_statistics&quot;][&quot;col_name&quot;][&quot;synth_mean&quot;]
# result[&quot;basic_statistics&quot;][&quot;col_name&quot;][&quot;mean_diff_pct&quot;]
</code></pre>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>num_cols</code></b> (list, optional): Numerical column names</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
</ul>
<hr />
<h2 id="fidelity-utility-metrics">Fidelity &amp; Utility Metrics</h2>
<h3 id="class-discriminatormetric"><kbd>class</kbd> <code>DiscriminatorMetric</code></h3>
<p>Trains a Random Forest classifier to distinguish real from synthetic data.</p>
<p>A score close to 0.5 means the synthetic data is indistinguishable from real data. A score close to 1.0 means the classifier easily tells them apart. Uses cross-validated hyperparameter tuning and reports mean/std over multiple random seeds.</p>
<pre><code class="language-python">from be_great.metrics import DiscriminatorMetric

result = DiscriminatorMetric(n_runs=10).compute(real_data, synthetic_data)
# result[&quot;discriminator_mean&quot;] -&gt; mean accuracy (0.5 = best)
# result[&quot;discriminator_std&quot;]  -&gt; standard deviation
</code></pre>
<p><strong>Args (__init__):</strong></p>
<ul>
<li><b><code>metric</code></b> (callable): Scoring function. Default: <code>accuracy_score</code></li>
<li><b><code>n_runs</code></b> (int): Number of evaluation runs. Default: 10</li>
<li><b><code>encoder</code></b> (type): Encoder for categorical features. Default: <code>OrdinalEncoder</code></li>
<li><b><code>encoder_params</code></b> (dict, optional): Encoder parameters</li>
</ul>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
<li><b><code>test_ratio</code></b> (float): Fraction used for testing. Default: 0.2</li>
<li><b><code>cv</code></b> (int): Cross-validation folds. Default: 5</li>
</ul>
<hr />
<h3 id="class-mlefficiency"><kbd>class</kbd> <code>MLEfficiency</code></h3>
<p>Machine learning efficiency — train on synthetic, test on real.</p>
<p>Measures the downstream utility of synthetic data. A model is trained entirely on the synthetic dataset and evaluated on a held-out real test set. The closer the score is to the performance achieved when training on real data, the higher the utility.</p>
<pre><code class="language-python">from be_great.metrics import MLEfficiency
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

result = MLEfficiency(
    model=RandomForestClassifier,
    metric=accuracy_score,
    model_params={&quot;n_estimators&quot;: 100},
).compute(real_data, synthetic_data, label_col=&quot;target&quot;)
# result[&quot;mle_mean&quot;]   -&gt; mean score across seeds
# result[&quot;mle_std&quot;]    -&gt; standard deviation
# result[&quot;mle_scores&quot;] -&gt; per-seed scores list
</code></pre>
<p><strong>Args (__init__):</strong></p>
<ul>
<li><b><code>model</code></b> (type): Sklearn-compatible model class</li>
<li><b><code>metric</code></b> (callable): Scoring function</li>
<li><b><code>model_params</code></b> (dict, optional): Model constructor parameters</li>
<li><b><code>encoder</code></b> (type): Encoder for categorical features. Default: <code>OrdinalEncoder</code></li>
<li><b><code>encoder_params</code></b> (dict, optional): Encoder parameters</li>
<li><b><code>normalize</code></b> (bool): Standard-scale continuous features. Default: False</li>
<li><b><code>use_proba</code></b> (bool): Use <code>predict_proba</code> instead of <code>predict</code>. Default: False</li>
<li><b><code>metric_params</code></b> (dict, optional): Extra kwargs for the scoring function</li>
</ul>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original training dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset (used for training)</li>
<li><b><code>label_col</code></b> (str): Target column name</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
<li><b><code>num_cols</code></b> (list, optional): Numerical column names</li>
<li><b><code>real_test_data</code></b> (DataFrame, optional): Separate real test set</li>
<li><b><code>test_ratio</code></b> (float): Split ratio if no separate test set. Default: 0.2</li>
<li><b><code>random_seeds</code></b> (list[int], optional): Seeds for multiple runs. Default: [512, 13, 23, 28, 21]</li>
</ul>
<hr />
<h2 id="privacy-metrics">Privacy Metrics</h2>
<h3 id="class-distancetoclosestrecord"><kbd>class</kbd> <code>DistanceToClosestRecord</code></h3>
<p>Distance to Closest Record (DCR).</p>
<p>For each synthetic record, computes the distance to the closest record in the real dataset. Uses L1 (Manhattan) distance for numerical features and Hamming distance for categorical features. Records with distance 0 are exact copies.</p>
<pre><code class="language-python">from be_great.metrics import DistanceToClosestRecord

result = DistanceToClosestRecord().compute(real_data, synthetic_data)
# result[&quot;dcr_mean&quot;]      -&gt; mean minimum distance
# result[&quot;dcr_std&quot;]       -&gt; standard deviation
# result[&quot;n_copies&quot;]      -&gt; number of exact copies
# result[&quot;ratio_copies&quot;]  -&gt; fraction of exact copies
</code></pre>
<p><strong>Args (__init__):</strong></p>
<ul>
<li><b><code>n_samples</code></b> (int): Number of synthetic samples to evaluate. 0 = use all. Default: 0</li>
<li><b><code>use_euclidean</code></b> (bool): Use L2 norm instead of L1 for numerical features. Default: False</li>
</ul>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>num_cols</code></b> (list, optional): Numerical column names</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
</ul>
<hr />
<h3 id="class-kanonymization"><kbd>class</kbd> <code>kAnonymization</code></h3>
<p>k-Anonymization metric.</p>
<p>Evaluates the k-anonymity of a dataset using KMeans clustering. Each record should be similar to at least k-1 other records on the quasi-identifying variables. Reports the ratio <code>k_synthetic / k_real</code> — a ratio &gt;= 1 means the synthetic data has at least as much k-anonymity as the real data.</p>
<pre><code class="language-python">from be_great.metrics import kAnonymization

result = kAnonymization().compute(real_data, synthetic_data)
# result[&quot;k_real&quot;]      -&gt; k value for original data
# result[&quot;k_synthetic&quot;] -&gt; k value for synthetic data
# result[&quot;k_ratio&quot;]     -&gt; syn / real ratio
</code></pre>
<p><strong>Args (__init__):</strong></p>
<ul>
<li><b><code>n_clusters_list</code></b> (list[int], optional): Cluster counts to evaluate. Default: [2, 5, 10, 15]</li>
</ul>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>sensitive_cols</code></b> (list, optional): Columns to exclude from quasi-identifiers</li>
</ul>
<hr />
<h3 id="class-ldiversity"><kbd>class</kbd> <code>lDiversity</code></h3>
<p>l-Diversity metric.</p>
<p>Measures the diversity of sensitive attribute values within each equivalence class. Uses KMeans to form groups and checks how many distinct sensitive values exist in the smallest group. Higher l-diversity means better protection against attribute inference.</p>
<pre><code class="language-python">from be_great.metrics import lDiversity

result = lDiversity(sensitive_col=&quot;diagnosis&quot;).compute(real_data, synthetic_data)
# result[&quot;l_real&quot;]      -&gt; l value for original data
# result[&quot;l_synthetic&quot;] -&gt; l value for synthetic data
# result[&quot;l_ratio&quot;]     -&gt; syn / real ratio
</code></pre>
<p><strong>Args (__init__):</strong></p>
<ul>
<li><b><code>sensitive_col</code></b> (str): Name of the sensitive attribute column</li>
<li><b><code>n_clusters_list</code></b> (list[int], optional): Cluster counts to evaluate. Default: [2, 5, 10, 15]</li>
</ul>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
</ul>
<hr />
<h3 id="class-identifiabilityscore"><kbd>class</kbd> <code>IdentifiabilityScore</code></h3>
<p>Identifiability score.</p>
<p>Measures the risk that a synthetic record can be linked back to a specific real record. Uses k-nearest neighbors and checks whether the closest real neighbor is significantly closer than the second closest (distance ratio below threshold).</p>
<pre><code class="language-python">from be_great.metrics import IdentifiabilityScore

result = IdentifiabilityScore().compute(real_data, synthetic_data)
# result[&quot;identifiability_score&quot;] -&gt; fraction of identifiable records
# result[&quot;mean_distance_ratio&quot;]   -&gt; average d1/d2 ratio
</code></pre>
<p><strong>Args (__init__):</strong></p>
<ul>
<li><b><code>n_neighbors</code></b> (int): Number of nearest neighbors. Default: 5</li>
<li><b><code>threshold_ratio</code></b> (float): Identifiability threshold. Default: 0.5</li>
</ul>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>num_cols</code></b> (list, optional): Numerical column names</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
</ul>
<hr />
<h3 id="class-deltapresence"><kbd>class</kbd> <code>DeltaPresence</code></h3>
<p>Delta-presence metric.</p>
<p>Measures how much the presence of an individual in the dataset can be inferred from the synthetic data. Computes the fraction of real records that have a near-exact match in the synthetic dataset within a distance threshold.</p>
<pre><code class="language-python">from be_great.metrics import DeltaPresence

result = DeltaPresence(threshold=0.5).compute(real_data, synthetic_data)
# result[&quot;delta_presence&quot;]        -&gt; fraction of real records with a match
# result[&quot;mean_nearest_distance&quot;] -&gt; average nearest distance
</code></pre>
<p><strong>Args (__init__):</strong></p>
<ul>
<li><b><code>threshold</code></b> (float): Distance threshold. 0.0 = exact match only. Default: 0.0</li>
</ul>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original dataset</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>num_cols</code></b> (list, optional): Numerical column names</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
</ul>
<hr />
<h3 id="class-membershipinference"><kbd>class</kbd> <code>MembershipInference</code></h3>
<p>Membership inference risk.</p>
<p>Simulates a membership inference attack: given a record, can an attacker determine whether it was in the training set? Compares distances from known-member records (train) and known-non-member records (holdout) to their nearest synthetic neighbors.</p>
<p>A score close to 0.5 means the attacker cannot distinguish members from non-members (good privacy). A score close to 1.0 means high membership inference risk.</p>
<pre><code class="language-python">from be_great.metrics import MembershipInference

result = MembershipInference().compute(real_data, synthetic_data)
# result[&quot;membership_inference_score&quot;] -&gt; attacker accuracy
# result[&quot;mean_member_distance&quot;]       -&gt; avg distance for members
# result[&quot;mean_non_member_distance&quot;]   -&gt; avg distance for non-members
</code></pre>
<p><strong>Args (__init__):</strong></p>
<ul>
<li><b><code>n_neighbors</code></b> (int): Number of nearest neighbors. Default: 1</li>
</ul>
<p><strong>Args (compute):</strong></p>
<ul>
<li><b><code>real_data</code></b> (DataFrame): Original training dataset (members)</li>
<li><b><code>synthetic_data</code></b> (DataFrame): Generated dataset</li>
<li><b><code>holdout_data</code></b> (DataFrame, optional): Non-member data. If None, real_data is split.</li>
<li><b><code>num_cols</code></b> (list, optional): Numerical column names</li>
<li><b><code>cat_cols</code></b> (list, optional): Categorical column names</li>
<li><b><code>holdout_ratio</code></b> (float): Split ratio if no holdout provided. Default: 0.5</li>
</ul>
<hr />
<p><em>This file was manually authored following the <a href="https://github.com/ml-tooling/lazydocs">lazydocs</a> convention.</em></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../great_utils/" class="btn btn-neutral float-left" title="Great utils"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../../examples/" class="btn btn-neutral float-right" title="Index">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../great_utils/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../examples/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
